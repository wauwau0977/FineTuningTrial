When logging performance-sensitive information like execution time, several considerations are important:

1.  **Logging Overhead:** Logging itself adds overhead. Excessive logging, especially within frequently executed methods, can significantly impact performance. Ensure logging is done judiciously and at appropriate levels (e.g., avoid DEBUG level in production).

2.  **Log Format:** Use a consistent and easily parseable log format. Include timestamps, thread IDs, and other relevant context. Structured logging (e.g., using JSON) is preferable for easier analysis and monitoring.

3.  **Aggregation:**  Rather than logging every single execution time, consider aggregating metrics (e.g., average, minimum, maximum, percentiles) over a period of time. This reduces log volume and provides more meaningful insights.

4. **Monitoring System Integration:** Ideally, send performance metrics to a dedicated monitoring system (e.g., Prometheus, Grafana, Datadog) rather than relying solely on log analysis.

In addition to the basic duration logging, other metrics that could be tracked to provide a more comprehensive understanding of the data polling process include:

*   **Number of Records Polled:** Track the number of `MeteoSwissEntity` objects retrieved in each polling cycle. This can help identify data volume trends and potential issues with the data source.
*   **Error Rate:**  Track the number of exceptions or errors encountered during the polling process. This can help identify recurring problems and potential data quality issues.
*   **Data Source Response Time:**  If possible, measure the response time of the external data source (e.g., MeteoSwiss API). This can help pinpoint performance bottlenecks outside of your application.
*   **Cache Hit/Miss Ratio:** If you are using caching, track the cache hit and miss rates to understand the effectiveness of your caching strategy.
*   **Queue Depth (if applicable):** If you are using a message queue to handle the data polling process, track the queue depth to identify potential backlogs.
* **Data Validation Failures**: Track the number of data records that fail validation checks, indicating potential issues with data quality or format.

By tracking these metrics, you can gain a more complete understanding of the data polling process, identify potential problems, and optimize performance.  Using a dedicated monitoring system is highly recommended for collecting, analyzing, and visualizing these metrics.